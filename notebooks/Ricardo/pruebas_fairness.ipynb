{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Equidad - Fairness - en el Aprendizaje Automático (ML) para problemas de clasificación\n",
    "\n",
    "\n",
    "* En ML, un modelo es ***justo*** o ***tiene equidad*** si ***sus predicciones son independientes de un cierto conjunto de variables*** que consideramos ***sensibles*** (ejm-> genero, etnia, religión, edad, estado civil, orientación sexual, etc.)\n",
    "\n",
    "\n",
    "* En problemas de clasificación, los modelos aprenden una función $h(X)$ para predecir una variable discreta $Y$, a partir de unas características conocidas $X$.\n",
    "\n",
    "\n",
    "## Criterios de Equidad\n",
    "\n",
    "\n",
    "* Se han definido 3 criterios de equidad (independencia, separación y suficiencia) para evaluar si un clasificador es justo; es decir, si sus predicciones no están influenciadas por alguna/s de las variables sensibles.\n",
    "\n",
    "\n",
    "* Para evaluar estos 3 criterios consideraremos:\n",
    "\n",
    "    + $X$: Conjunto de variables (características) que describen a un elemento.\n",
    "    + $A$: Variable aleatoria protegida o sensible (genero, etnia, edad, etc.).\n",
    "    + $h(X)$: Modelo de clasificación (función predictora).\n",
    "    + $Y$: Predicción del clasificador (y_predict)\n",
    "    + $T$: Target (y_true)\n",
    "    \n",
    "\n",
    "* Para ver un ejemplo de cálculo de estos criterios, usaremos el siguiente \"dataset\" de ejemplo donde:\n",
    "\n",
    "    + $A -> genero$: toma los valores $\\{'Hombre', 'Mujer'\\}$\n",
    "    + $T -> target$: es binario y toma los valores $\\{0: negativo, 1: positivo\\}$ \n",
    "    + $Y -> predicción$: es binario y toma los valores $\\{0: negativo, 1: positivo\\}$ \n",
    "    \n",
    "\n",
    "|id|genero|T: target|Y: predicción|\n",
    "|--|--|--|--|\n",
    "|1|Hombre|1|1|\n",
    "|2|Hombre|1|1|\n",
    "|3|Mujer|0|0|\n",
    "|4|Hombre|0|1|\n",
    "|5|Mujer|1|0|\n",
    "|6|Hombre|1|0|\n",
    "|7|Hombre|1|1|\n",
    "|8|Mujer|1|1|\n",
    "|9|Hombre|0|0|\n",
    "|10|Mujer|0|0|\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 1.- Independencia\n",
    "\n",
    "* Decimos que las variables aleatorias $(Y,A)$ satisfacen la independencia si la variable sensible $A$ es estadísticamente independiente a la predicción $Y$.\n",
    "\n",
    "\n",
    "$$P(Y=y \\mid  A=a) = P(Y=y \\mid  A=b)$$\n",
    "\n",
    "#### ¿Cumple el criterio de Independencia?\n",
    "\n",
    "\n",
    "* Evidentemente en cualquier caso real nunca van a ser las probabilidades iguales, por lo que hay que establecer un umbral $\\epsilon$ en el que se considere que cumple o no el criterio de independencia.\n",
    "\n",
    "\n",
    "* Por tanto el modelo cumple el criterio de independencia si:\n",
    "\n",
    "\n",
    "$$\\left | \\  P(Y=y \\mid  A=a) - P(Y=y \\mid  A=b) \\ \\right | \\leq  \\epsilon$$\n",
    "\n",
    "\n",
    "#### Ejemplo:\n",
    "\n",
    "\n",
    "* *La probabilidad de ser clasificado por el algoritmo en cada uno de los grupos* $\\{0: negativo, 1: positivo\\}$ *es la misma para dos elementos (individuos) con características sensibles distinta*s $\\{'Hombre', 'Mujer'\\}$.\n",
    "\n",
    "\n",
    "$$P(Y=1 \\mid  A=Hombre) = P(Y=1 \\mid  A=Mujer)$$\n",
    "\n",
    "\n",
    "* $P(Y=1 \\mid  A=Hombre) = \\frac{4}{6} = \\frac{4 \\ predicción \\ =1}{6 \\ hombres} = 0.66$:\n",
    "\n",
    "|id|genero|Y: predicción|\n",
    "|--|--|--|--|\n",
    "|1|Hombre|1|\n",
    "|2|Hombre|1|\n",
    "|4|Hombre|1|\n",
    "|6|Hombre|0|\n",
    "|7|Hombre|1|\n",
    "|9|Hombre|0|\n",
    "\n",
    "* $P(Y=1 \\mid  A=Mujer) = \\frac{1}{4} = \\frac{1 \\ predicción \\ =1}{4 \\ mujeres} = 0.25$:\n",
    "\n",
    "|id|genero|Y: predicción|\n",
    "|--|--|--|--|\n",
    "|3|Mujer|0|\n",
    "|5|Mujer|0|\n",
    "|8|Mujer|1|\n",
    "|10|Mujer|0|\n",
    "\n",
    "\n",
    "* Por tanto:\n",
    "\n",
    "$$ \\frac{4}{6} \\neq \\frac{1}{4} \\rightarrow 0.66 \\neq 0.25$$\n",
    "\n",
    "\n",
    "\n",
    "* De manera similar, podemos ver la independencia frente al target (y_true) para saber si la realidad esta sesgada:\n",
    "\n",
    "\n",
    "$$P(T=t \\mid  A=a) = P(T=t \\mid  A=b)$$\n",
    "\n",
    "\n",
    "$$P(T=1 \\mid  A=Hombre) = P(T=1 \\mid  A=Mujer)$$ \n",
    "\n",
    "\n",
    "$$\\frac{4}{6} \\neq \\frac{2}{4} \\rightarrow 0.66 \\neq 0.5$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 2.- Separación\n",
    "\n",
    "\n",
    "* Decimos que las variables aleatorias $(Y,A,T)$ satisfacen la separación si la variable sensible $A$ es estadisticamente independientes a la predicción $Y$ dado el valor objetivo $T$.\n",
    "\n",
    "\n",
    "* \"*La probabilidad de predecir un Verdadero Positivo y un Falso Positivo para cada grupo debe de ser la misma*\".\n",
    "\n",
    "$$P(Y=1 \\mid T=1, A=a) = P(Y=1 \\mid T=1, A=b)$$\n",
    "$$P(Y=1 \\mid T=0, A=a) = P(Y=1 \\mid T=0, A=b)$$\n",
    "\n",
    "\n",
    "* Una ligera \"simplificación\" de este criterio sería la de tomar solo la probablidad de Verdaderos Positivos, asumiendo que \"elementos similares\" deben de ser tratados por igual.\n",
    "\n",
    "#### ¿Cumple el criterio de Separación?\n",
    "\n",
    "\n",
    "* Una relajación del criterio de separación vendría dado por que la diferencia entre tasas no superase un determinado umbral $\\epsilon$\n",
    "\n",
    "\n",
    "$$\\left | \\  P(Y=1 \\mid T=1, A=a) - P(Y=1 \\mid T=1, A=b) \\ \\right | \\leq  \\epsilon$$\n",
    "\n",
    "\n",
    "\n",
    "#### Ejemplo:\n",
    "\n",
    "\n",
    "$$P(Y=1 \\mid T=1, A=Hombre) = P(Y=1 \\mid T=1, A=Mujer)$$\n",
    "\n",
    "\n",
    "* $P(Y=1 \\mid T=1, A=Hombre) = \\frac{3}{4} = \\frac{3 \\ predicción \\ = 1}{4 \\ hombres \\ target \\ =1} = 0.75$:\n",
    "\n",
    "\n",
    "|id|genero|T: target|Y: predicción|\n",
    "|--|--|--|--|\n",
    "|1|Hombre|1|1|\n",
    "|2|Hombre|1|1|\n",
    "|6|Hombre|1|0|\n",
    "|7|Hombre|1|1|\n",
    "\n",
    "\n",
    "* $P(Y=1 \\mid T=1, A=Mujer) = \\frac{1}{2} = \\frac{1 \\ predicción \\ = 1}{2 \\ mujeres \\ target=1} = 0.5$:\n",
    "\n",
    "\n",
    "|id|genero|T: target|Y: predicción|\n",
    "|--|--|--|--|\n",
    "|5|Mujer|1|0|\n",
    "|8|Mujer|1|1|\n",
    "\n",
    "\n",
    "* Por tanto:\n",
    "\n",
    "$$ \\frac{3}{4} \\neq \\frac{1}{2} \\rightarrow 0.75 \\neq 0.5$$\n",
    "\n",
    "\n",
    "### 3.- Suficiencia\n",
    "\n",
    "\n",
    "* Decimos que las variables aleatorias $(Y,A,T)$ satisfacen la suficiencia si la variable sensible $A$ es estadísticamente independiente al valor objetivo $T$ dada la predicción $Y$.\n",
    "\n",
    "\n",
    "$$P(T=1 \\mid Y=1, A=a) = P(T=1 \\mid Y=1, A=b)$$\n",
    "\n",
    "\n",
    "* Esto significa que la probabilidad de estar en realidad en cada uno de los grupos es la misma para dos individuos con características sensibles distintas dado que la predicción los englobe en el mismo grupo.\n",
    "\n",
    "\n",
    "#### ¿Cumple el criterio de Suficiencia?\n",
    "\n",
    "\n",
    "* Una relajación del criterio de suficiencia vendría dado por que la diferencia entre tasas no superase un determinado umbral $\\epsilon$\n",
    "\n",
    "\n",
    "$$\\left | \\  P(T=1 \\mid Y=1, A=a) - P(T=1 \\mid Y=1, A=b) \\ \\right | \\leq  \\epsilon$$\n",
    "\n",
    "\n",
    "#### Ejemplo:\n",
    "\n",
    "\n",
    "$$P(T=1 \\mid Y=1, A=Hombre) = P(T=1 \\mid Y=1, A=Mujer)$$\n",
    "\n",
    "\n",
    "\n",
    "* $P(T=1 \\mid Y=1, A=Hombre) = \\frac{3}{4} = \\frac{3 \\ target = 1}{4 \\ hombres \\ prediccion \\ =1} = 0.75$\n",
    "\n",
    "|id|genero|T: target|Y: predicción|\n",
    "|--|--|--|--|\n",
    "|1|Hombre|1|1|\n",
    "|2|Hombre|1|1|\n",
    "|4|Hombre|0|1|\n",
    "|7|Hombre|1|1|\n",
    "\n",
    "\n",
    "* $P(T=1 \\mid Y=1, A=Mujer) = \\frac{1}{1} = \\frac{1 \\ target = 1}{1 \\ Mujer \\ prediccion \\ =1} = 1.0$\n",
    "\n",
    "\n",
    "|id|genero|T: target|Y: predicción|\n",
    "|--|--|--|--|\n",
    "|8|Mujer|1|1|\n",
    "\n",
    "\n",
    "* Por tanto:\n",
    "\n",
    "$$ \\frac{3}{4} \\neq \\frac{1}{1} \\rightarrow 0.75 \\neq 1.0$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# IMPLEMENTACIÓN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genero</th>\n",
       "      <th>Color</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hombre</td>\n",
       "      <td>AZUL</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hombre</td>\n",
       "      <td>AZUL</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mujer</td>\n",
       "      <td>VERDE</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hombre</td>\n",
       "      <td>AZUL</td>\n",
       "      <td>NO</td>\n",
       "      <td>SI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mujer</td>\n",
       "      <td>AZUL</td>\n",
       "      <td>SI</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hombre</td>\n",
       "      <td>VERDE</td>\n",
       "      <td>SI</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hombre</td>\n",
       "      <td>ROSA</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mujer</td>\n",
       "      <td>ROSA</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hombre</td>\n",
       "      <td>ROSA</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mujer</td>\n",
       "      <td>ROSA</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Genero  Color y_true y_predict\n",
       "0  Hombre   AZUL     SI        SI\n",
       "1  Hombre   AZUL     SI        SI\n",
       "2   Mujer  VERDE     NO        NO\n",
       "3  Hombre   AZUL     NO        SI\n",
       "4   Mujer   AZUL     SI        NO\n",
       "5  Hombre  VERDE     SI        NO\n",
       "6  Hombre   ROSA     SI        SI\n",
       "7   Mujer   ROSA     SI        SI\n",
       "8  Hombre   ROSA     NO        NO\n",
       "9   Mujer   ROSA     NO        NO"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Definimos el Dataset de ejemplo\n",
    "df_dataset = pd.DataFrame(\n",
    "    {\n",
    "        'Genero': ['Hombre', 'Hombre', 'Mujer', 'Hombre', 'Mujer', 'Hombre', 'Hombre', 'Mujer', 'Hombre', 'Mujer'],\n",
    "        'Color':  ['AZUL',   'AZUL',   'VERDE', 'AZUL',   'AZUL',   'VERDE', 'ROSA',    'ROSA', 'ROSA',   'ROSA'],\n",
    "        'y_true':    ['SI', 'SI', 'NO', 'NO', 'SI', 'SI', 'SI', 'SI', 'NO', 'NO'],\n",
    "        'y_predict': ['SI', 'SI', 'NO', 'SI', 'NO', 'NO', 'SI', 'SI', 'NO', 'NO']}, \n",
    "    columns=['Genero', 'Color', 'y_true', 'y_predict'])\n",
    "\n",
    "df_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genero</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROJO</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROJO</td>\n",
       "      <td>SI</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROJO</td>\n",
       "      <td>NO</td>\n",
       "      <td>XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROJO</td>\n",
       "      <td>XX</td>\n",
       "      <td>SI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AZUL</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AZUL</td>\n",
       "      <td>SI</td>\n",
       "      <td>XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AZUL</td>\n",
       "      <td>NO</td>\n",
       "      <td>SI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AZUL</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AZUL</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VERDE</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VERDE</td>\n",
       "      <td>NO</td>\n",
       "      <td>SI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>VERDE</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Genero y_true y_predict\n",
       "0    ROJO     SI        SI\n",
       "1    ROJO     SI        NO\n",
       "2    ROJO     NO        XX\n",
       "3    ROJO     XX        SI\n",
       "4    AZUL     SI        SI\n",
       "5    AZUL     SI        XX\n",
       "6    AZUL     NO        SI\n",
       "7    AZUL     NO        NO\n",
       "8    AZUL     XX        XX\n",
       "9   VERDE     SI        SI\n",
       "10  VERDE     NO        SI\n",
       "11  VERDE     XX        XX"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definimos el Dataset de ejemplo\n",
    "df_dataset2 = pd.DataFrame(\n",
    "    {\n",
    "        'Genero': ['ROJO', 'ROJO', 'ROJO', 'ROJO', 'AZUL', 'AZUL', 'AZUL', 'AZUL', 'AZUL', 'VERDE', 'VERDE', 'VERDE'],\n",
    "        'y_true':    ['SI', 'SI', 'NO', 'XX', 'SI', 'SI', 'NO', 'NO', 'XX', 'SI', 'NO', 'XX'],\n",
    "        'y_predict': ['SI', 'NO', 'XX', 'SI', 'SI', 'XX', 'SI', 'NO', 'XX', 'SI', 'SI', 'XX']}, \n",
    "    columns=['Genero', 'y_true', 'y_predict'])\n",
    "\n",
    "df_dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BINARY: Genero - [Hombre | Mujer] - SI\n",
      "0.41666666666666663\n",
      "0.25\n",
      "0.25\n",
      "BINARY: Genero - [Hombre | Mujer] - NO\n",
      "0.4166666666666667\n",
      "0.5\n",
      "0.16666666666666663\n",
      "MULTIPLE: Color - AZUL - SI\n",
      "WARNING: Probability P(Y=SI|A=OTHER) result is Zero, because ZeroDivisionError\n",
      "WARNING: Probability P(Y=SI|T=SI, A=OTHER) result is Zero, because ZeroDivisionError\n",
      "WARNING: Probability P(T=SI|Y=SI, A=OTHER) result is Zero, because ZeroDivisionError\n",
      "0.75\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "MULTIPLE: Color - VERDE - SI\n",
      "WARNING: Probability P(Y=SI|A=VERDE) result is Zero, because ZeroDivisionError\n",
      "WARNING: Probability P(Y=SI|T=SI, A=VERDE) result is Zero, because ZeroDivisionError\n",
      "WARNING: Probability P(T=SI|Y=SI, A=VERDE) result is Zero, because ZeroDivisionError\n",
      "0.3333333333333333\n",
      "0.6666666666666666\n",
      "1.0\n",
      "MULTIPLE: Color - ROSA - SI\n",
      "WARNING: Probability P(Y=SI|A=ROSA) result is Zero, because ZeroDivisionError\n",
      "WARNING: Probability P(Y=SI|T=SI, A=ROSA) result is Zero, because ZeroDivisionError\n",
      "WARNING: Probability P(T=SI|Y=SI, A=ROSA) result is Zero, because ZeroDivisionError\n",
      "0.5\n",
      "0.6666666666666666\n",
      "0.8\n",
      "MULTIPLE: Color - AZUL - NO\n",
      "WARNING: Probability P(Y=NO|A=AZUL) result is Zero, because ZeroDivisionError\n",
      "WARNING: Probability P(Y=NO|T=NO, A=AZUL) result is Zero, because ZeroDivisionError\n",
      "WARNING: Probability P(T=NO|Y=NO, A=AZUL) result is Zero, because ZeroDivisionError\n",
      "0.5\n",
      "0.75\n",
      "0.6\n",
      "MULTIPLE: Color - VERDE - NO\n",
      "WARNING: Probability P(Y=NO|A=VERDE) result is Zero, because ZeroDivisionError\n",
      "WARNING: Probability P(Y=NO|T=NO, A=VERDE) result is Zero, because ZeroDivisionError\n",
      "WARNING: Probability P(T=NO|Y=NO, A=VERDE) result is Zero, because ZeroDivisionError\n",
      "0.5\n",
      "0.75\n",
      "0.6\n",
      "MULTIPLE: Color - ROSA - NO\n",
      "WARNING: Probability P(Y=NO|A=ROSA) result is Zero, because ZeroDivisionError\n",
      "WARNING: Probability P(Y=NO|T=NO, A=ROSA) result is Zero, because ZeroDivisionError\n",
      "WARNING: Probability P(T=NO|Y=NO, A=ROSA) result is Zero, because ZeroDivisionError\n",
      "0.5\n",
      "0.75\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "# EXCEPCIONES: Tratar divisiones entre 0\n",
    "\n",
    "class Fairness:\n",
    "    \n",
    "    __BINARY = 2\n",
    "    __OTHER = 'OTHER'\n",
    "    __FAIRNESS_SCORE = {'A+': 0.01, 'A': 0.03, 'B': 0.05, 'C': 0.1, 'D': 0.2, 'E': 1.0}\n",
    "\n",
    "    def __init__(self, fairness_params: Dict):\n",
    "        self.fairness_params = fairness_params\n",
    "        self.target_values = None\n",
    "        self.confusion_matrix = None\n",
    "        self.correlation_matrix = None\n",
    "        self.independence_info = list()\n",
    "        self.separation_info = list()\n",
    "        self.sufficience_info = list()\n",
    "        self.independence_score = list()\n",
    "        self.separation_score = list()\n",
    "        self.sufficience_score = list()\n",
    "        \n",
    "    \n",
    "            \n",
    "    def pre_processing(self, df: pd.DataFrame, sensitive_cols: List[str], target_col: str, predict_col: str) -> None:\n",
    "        \"\"\"Función que realiza los procesamientos de datos previos a los cálculos \"core\" de la clase\n",
    "        \"\"\"\n",
    "        # Obtengo los distintos valores del target\n",
    "        self.target_values = df[predict_col].unique()\n",
    "        \n",
    "        # En las filas se representa el target, en las columnas las predicciones\n",
    "        self.confusion_matrix = pd.crosstab(df[target_col], \n",
    "                                            df[predict_col], \n",
    "                                            rownames=[target_col], \n",
    "                                            colnames=[predict_col])\n",
    "    \n",
    "    def in_processing(self, df: pd.DataFrame, sensitive_cols: List[str], target_col: str, predict_col: str) -> None:\n",
    "        \"\"\"Función que realiza los procesamientos \"cores\" de la clase\n",
    "        \"\"\"\n",
    "        # Para cada una de las variables sensibles\n",
    "        for sensitive_col in sensitive_cols:\n",
    "            \n",
    "            # Obtengo los distintos valores de la variable sensible; para ver si es o no binaria\n",
    "            sensitive_values = df[sensitive_col].unique()\n",
    "            is_sensitive_col_binary = True if len(sensitive_values) == self.__BINARY else False\n",
    "            \n",
    "            # Para cada uno de los Targets\n",
    "            for target_label in self.target_values:\n",
    "            \n",
    "                # Para cada uno de los valores sensibles\n",
    "                for sensitive_value in sensitive_values:\n",
    "                \n",
    "                    # Binarizo las predicciones y target del Dataset\n",
    "                    df_process = deepcopy(df)\n",
    "                    df_process.loc[df_process[target_col] != target_label, target_col] = self.__OTHER\n",
    "                    df_process.loc[df_process[predict_col] != target_label, predict_col] = self.__OTHER\n",
    "                    \n",
    "                    if is_sensitive_col_binary:\n",
    "                        print(\"BINARY: {} - [{}] - {}\".format(sensitive_col, \" | \".join(sensitive_values), target_label))\n",
    "                        self.process_sensitive_column(df=df_process,\n",
    "                                                      sensitive_col=sensitive_col,\n",
    "                                                      target_col=target_col,\n",
    "                                                      predict_col=predict_col,\n",
    "                                                      target_label=target_label,\n",
    "                                                      sensitive_values=sensitive_values,\n",
    "                                                      is_sensitive_col_binary=True)\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"MULTIPLE: {} - {} - {}\".format(sensitive_col, sensitive_value, target_label))\n",
    "                        # Binarización de los valores sensibles para analizarlos de 1 en 1\n",
    "                        df.loc[df[sensitive_col] != sensitive_value, sensitive_col] = self.__OTHER\n",
    "                        self.process_sensitive_column(df=df_process,\n",
    "                                                      sensitive_col=sensitive_col,\n",
    "                                                      target_col=target_col,\n",
    "                                                      predict_col=predict_col,\n",
    "                                                      target_label=target_label,\n",
    "                                                      sensitive_values=[sensitive_value, self.__OTHER],\n",
    "                                                      is_sensitive_col_binary=False)\n",
    "\n",
    "    \n",
    "    def post_processing(self, df: pd.DataFrame, sensitive_cols: List[str], target_col: str, predict_col: str) -> None:\n",
    "        \"\"\"Función que realiza los procesamientos de datos posteriores a los cálculos \"core\" de la clase\n",
    "        \"\"\"\n",
    "        pass    \n",
    "    \n",
    "    def process_sensitive_column(self, df: pd.DataFrame, sensitive_col: str, target_col: str, predict_col: str, \n",
    "                                 target_label: str, sensitive_values: List[str], is_sensitive_col_binary: bool) -> None:\n",
    "        \"\"\"Función que tiene que escribir en los atributos de la clase correspondientes los diferentes valores de los\n",
    "        criterios para cada par de valores \"valorVariable-valorTarget\"\n",
    "        \"\"\"\n",
    "        # Obtengo los resultados\n",
    "        independence, separation, sufficience = self.fit_metrics(df=df,\n",
    "                                                                 sensitive_col=sensitive_col,\n",
    "                                                                 target_col=target_col,\n",
    "                                                                 predict_col=predict_col,\n",
    "                                                                 target_label=target_label,\n",
    "                                                                 sensitive_values=sensitive_values)\n",
    "        print(independence)\n",
    "        print(separation)\n",
    "        print(sufficience)\n",
    "                    \n",
    "    def fit_independence(self, df: pd.DataFrame, sensitive_col: str, predict_col: str, target_label: str, \n",
    "                         sensitive_values: List[str]) -> float:\n",
    "        \"\"\"\n",
    "        A-> Variable sensible\n",
    "        Y-> Predicción\n",
    "        P(Y=y∣A=a) == P(Y=y∣A=b)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            prob_a = (((df[(df[sensitive_col]==sensitive_values[0]) & (df[predict_col]==target_label)].shape[0])) / \n",
    "                      (df[df[sensitive_col]==sensitive_values[0]].shape[0]))\n",
    "        except ZeroDivisionError:\n",
    "            prob_a = 0\n",
    "            print('WARNING: Probability P(Y={}|A={}) result is Zero, because ZeroDivisionError'\n",
    "                  .format(target_label, sensitive_values[0]))\n",
    "            \n",
    "        try:\n",
    "            prob_b = (((df[(df[sensitive_col]==sensitive_values[1]) & (df[predict_col]==target_label)].shape[0])) / \n",
    "                      (df[df[sensitive_col]==sensitive_values[1]].shape[0]))\n",
    "        except ZeroDivisionError:\n",
    "            prob_b = 0\n",
    "            print('WARNING: Probability P(Y={}|A={}) result is Zero, because ZeroDivisionError'\n",
    "                  .format(target_label, sensitive_values[1]))\n",
    "            \n",
    "#         print('\\tProb A = {}'.format(prob_a))\n",
    "#         print('\\tProb B = {}'.format(prob_b))\n",
    "        return abs(prob_a - prob_b)\n",
    "    \n",
    "    def fit_separation(self, df: pd.DataFrame, sensitive_col: str, target_col: str, predict_col: str, target_label: str, \n",
    "                       sensitive_values: List[str]) -> float:\n",
    "        \"\"\"      \n",
    "        A-> Variable sensible\n",
    "        Y-> Predicción\n",
    "        T-> Target\n",
    "        P(Y=1∣T=1,A=a)=P(Y=1∣T=1,A=b)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            prob_a = ((df[(df[sensitive_col]==sensitive_values[0]) & (df[target_col]==target_label) & \n",
    "                          (df[predict_col]==target_label)]).shape[0] / \n",
    "                      (df[(df[sensitive_col]==sensitive_values[0]) & (df[target_col]==target_label)]).shape[0])\n",
    "        except ZeroDivisionError:\n",
    "            prob_a = 0\n",
    "            print('WARNING: Probability P(Y={}|T={}, A={}) result is Zero, because ZeroDivisionError'\n",
    "                  .format(target_label, target_label, sensitive_values[0]))\n",
    "            \n",
    "        try:\n",
    "            prob_b = ((df[(df[sensitive_col]==sensitive_values[1]) & (df[target_col]==target_label) &\n",
    "                          (df[predict_col]==target_label)]).shape[0] / \n",
    "                      (df[(df[sensitive_col]==sensitive_values[1]) & (df[target_col]==target_label)]).shape[0])\n",
    "        except ZeroDivisionError:\n",
    "            prob_b = 0\n",
    "            print('WARNING: Probability P(Y={}|T={}, A={}) result is Zero, because ZeroDivisionError'\n",
    "                  .format(target_label, target_label, sensitive_values[1]))\n",
    "        \n",
    "#         print('\\tProb A = {}'.format(prob_a))\n",
    "#         print('\\tProb B = {}'.format(prob_b))\n",
    "        return abs(prob_a - prob_b)\n",
    "    \n",
    "    def fit_sufficiency(self, df: pd.DataFrame, sensitive_col: str, target_col: str, predict_col: str, target_label: str, \n",
    "                        sensitive_values: List[str]) -> float:\n",
    "        \"\"\"\n",
    "        A-> Variable sensible\n",
    "        Y-> Predicción\n",
    "        T-> Target\n",
    "        P(T=1∣Y=1,A=a)=P(T=1∣Y=1,A=b)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            prob_a = ((df[(df[sensitive_col]==sensitive_values[0]) & (df[target_col]==target_label) &\n",
    "                          (df[predict_col]==target_label)]).shape[0] / \n",
    "                      (df[(df[sensitive_col]==sensitive_values[0]) & (df[predict_col]==target_label)]).shape[0])\n",
    "        except ZeroDivisionError:\n",
    "            prob_a = 0\n",
    "            print('WARNING: Probability P(T={}|Y={}, A={}) result is Zero, because ZeroDivisionError'\n",
    "                  .format(target_label, target_label, sensitive_values[0]))\n",
    "            \n",
    "        try:    \n",
    "            prob_b = ((df[(df[sensitive_col]==sensitive_values[1]) & (df[target_col]==target_label) &\n",
    "                          (df[predict_col]==target_label)]).shape[0] / \n",
    "                      (df[(df[sensitive_col]==sensitive_values[1]) & (df[predict_col]==target_label)]).shape[0])\n",
    "        except ZeroDivisionError:\n",
    "            prob_b = 0\n",
    "            print('WARNING: Probability P(T={}|Y={}, A={}) result is Zero, because ZeroDivisionError'\n",
    "                  .format(target_label, target_label, sensitive_values[1]))\n",
    "        \n",
    "#         print('\\tProb A = {}'.format(prob_a))\n",
    "#         print('\\tProb B = {}'.format(prob_b))\n",
    "        return abs(prob_a - prob_b)\n",
    "\n",
    "\n",
    "    def fit_metrics(self, df: pd.DataFrame, sensitive_col: str, target_col: str, predict_col: str, target_label: str, \n",
    "                    sensitive_values: List[str]) -> Tuple[float, float, float]:\n",
    "        \n",
    "        independence = self.fit_independence(df=df,\n",
    "                                             sensitive_col=sensitive_col,\n",
    "                                             predict_col=predict_col,\n",
    "                                             target_label=target_label,\n",
    "                                             sensitive_values=sensitive_values)\n",
    "#         print(\"Independence: {}\\n\".format(independence))\n",
    "        separation = self.fit_separation(df=df,\n",
    "                                         sensitive_col=sensitive_col,\n",
    "                                         target_col=target_col,\n",
    "                                         predict_col=predict_col,\n",
    "                                         target_label=target_label,\n",
    "                                         sensitive_values=sensitive_values)\n",
    "#         print(\"Separation: {}\\n\".format(separation))\n",
    "        sufficience = self.fit_sufficiency(df=df,\n",
    "                                           sensitive_col=sensitive_col,\n",
    "                                           target_col=target_col,\n",
    "                                           predict_col=predict_col,\n",
    "                                           target_label=target_label,\n",
    "                                           sensitive_values=sensitive_values)\n",
    "#         print(\"Sufficience: {}\\n\\n\".format(sufficience))\n",
    "        \n",
    "        return independence, separation, sufficience\n",
    "    \n",
    "    def score_weight(self, df: pd.DataFrame, sensitive_col: str, \n",
    "                     predict_col: str, ground_truth: str, groupby_cols: List[str]) -> float:\n",
    "        \"\"\"\n",
    "        Función para calcular el porcentaje (peso) que supone el cálculo de algún criterio respecto se su\n",
    "        predicción y variable sensible\n",
    "        \"\"\"\n",
    "        dfp = df.groupby(groupby_cols)[sensitive_col].agg({'count' : 'count'}).reset_index()\n",
    "        dfp['pct'] = dfp['count'] / dfp['count'].sum()\n",
    "        return dfp[dfp[predict_col] == ground_truth]['pct'].iloc[0]\n",
    "\n",
    "\n",
    "    def get_fairness_score(self, score: float, fairness_score: Dict) -> str:\n",
    "            \"\"\"Función de devuelve la categoria Fairness en función de us Score dado\n",
    "            \"\"\"\n",
    "            # Ordenamos el diccionario con los valores de menor a mayor\n",
    "            try:\n",
    "                fairness_score = dict(sorted(fairness_score.items(), key=lambda item: item[1], reverse=False))\n",
    "            except:\n",
    "                print('Error con el diccionario de Fairness Scores')\n",
    "\n",
    "            if fairness_score[(list(fairness_score.keys())[-1])] < score:\n",
    "                print('ERROR: El score dado es superior al valor máximo. Se devuelve la categoría más alta por defecto')\n",
    "                return (list(fairness_score.keys())[-1])\n",
    "            else:   \n",
    "                for k, v in fairness_score.items():\n",
    "                    if score < v:\n",
    "                        return k\n",
    "                        break\n",
    "            \n",
    "            \n",
    "    def fit(self, df: pd.DataFrame, sensitive_cols: List[str], target_col: str, predict_col: str) -> None:\n",
    "        \n",
    "        self.pre_processing(df=df, \n",
    "                            sensitive_cols=sensitive_cols, \n",
    "                            target_col=target_col, \n",
    "                            predict_col=predict_col)\n",
    "        \n",
    "        self.in_processing(df=df, \n",
    "                            sensitive_cols=sensitive_cols, \n",
    "                            target_col=target_col, \n",
    "                            predict_col=predict_col)\n",
    "        \n",
    "        self.post_processing(df=df, \n",
    "                            sensitive_cols=sensitive_cols, \n",
    "                            target_col=target_col, \n",
    "                            predict_col=predict_col)\n",
    "                   \n",
    "\n",
    "fairness = Fairness(fairness_params={})\n",
    "dict_result = fairness.fit(df=df_dataset,\n",
    "                           sensitive_cols=['Genero', 'Color'],\n",
    "                           target_col='y_true', \n",
    "                           predict_col='y_predict')\n",
    "\n",
    "df_result = pd.DataFrame.from_dict(dict_result)\n",
    "df_result\n",
    "dict_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y_predict</th>\n",
       "      <th>NO</th>\n",
       "      <th>SI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_true</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NO</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y_predict  NO  SI\n",
       "y_true           \n",
       "NO          3   1\n",
       "SI          2   4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fairness.confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "# EXCEPCIONES: Tratar divisiones entre 0\n",
    "\n",
    "class Fairness:\n",
    "    \n",
    "    __BINARY = 2\n",
    "    __OTHER = 'OTHER'\n",
    "    __FAIRNESS_SCORE = {'A+': 0.01, 'A': 0.03, 'B': 0.05, 'C': 0.1, 'D': 0.2, 'E': 1.0}\n",
    "\n",
    "    def __init__(self, fairness_params: Dict):\n",
    "        self.fairness_params = fairness_params\n",
    "        self.target_values = None\n",
    "        self.confusion_matrix = None\n",
    "        self.correlation_matrix = None\n",
    "        self.independence_info = None\n",
    "        self.separation_info = None\n",
    "        self.sufficience_info = None\n",
    "        self.independence_score = None\n",
    "        self.separation_score = None\n",
    "        self.sufficience_score = None\n",
    "        \n",
    "    \n",
    "            \n",
    "    def pre_processing(self, df_dataset: pd.DataFrame, sensitive_cols: List[str], target_col: str, predict_col: str):\n",
    "        \"\"\"Función que realiza los procesamientos de datos previos a los cálculos \"core\" de la clase\n",
    "        \"\"\"\n",
    "        # Obtengo los distintos valores del target\n",
    "        self.target_values = df_dataset[predict_col].unique()\n",
    "        \n",
    "        # En las filas se representa el target, en las columnas las predicciones\n",
    "        self.confusion_matrix = pd.crosstab(df_dataset[target_col], \n",
    "                                            df_dataset[predict_col], \n",
    "                                            rownames=[target_col], \n",
    "                                            colnames=[predict_col])\n",
    "    \n",
    "    def in_processing(self, df_dataset: pd.DataFrame, sensitive_cols: List[str], target_col: str, predict_col: str):\n",
    "        \"\"\"Función que realiza los procesamientos \"cores\" de la clase\n",
    "        \"\"\"\n",
    "        # Para cada una de las variables sensibles\n",
    "        for sensitive_col in sensitive_cols:\n",
    "            \n",
    "            # Obtengo los distintos valores de la variable sensible; para ver si es o no binaria\n",
    "            sensitive_values = df_dataset[sensitive_col].unique()\n",
    "            is_sensitive_col_binary = True if len(sensitive_values) == self.__BINARY else False\n",
    "            \n",
    "            # Para cada uno de los valores sensibles\n",
    "            for sensitive_value in sensitive_values:\n",
    "                \n",
    "                # Para cada uno de los Targets\n",
    "                for target_value in self.target_values:\n",
    "                    \n",
    "                    # Binarizo las predicciones y target del Dataset\n",
    "                    df = deepcopy(df_dataset)\n",
    "                    df.loc[df[target_col] != target_value, target_col] = self.__OTHER\n",
    "                    df.loc[df[predict_col] != target_value, predict_col] = self.__OTHER\n",
    "                    \n",
    "                    print(\"{} - {} - {}\".format(sensitive_col, sensitive_value, target_value))\n",
    "                    print(df)\n",
    "    \n",
    "    def post_processing(self, df_dataset: pd.DataFrame, sensitive_cols: List[str], target_col: str, predict_col: str):\n",
    "        \"\"\"Función que realiza los procesamientos de datos posteriores a los cálculos \"core\" de la clase\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def get_fairness_score(self, score: float, fairness_score: Dict):\n",
    "        \"\"\"Función de devuelve la categoria Fairness en función de us Score dado\n",
    "        \"\"\"\n",
    "        # Ordenamos el diccionario con los valores de menor a mayor\n",
    "        try:\n",
    "            fairness_score = dict(sorted(fairness_score.items(), key=lambda item: item[1], reverse=False))\n",
    "        except:\n",
    "            print('Error con el diccionario de Fairness Scores')\n",
    "\n",
    "        if fairness_score[(list(fairness_score.keys())[-1])] < score:\n",
    "            print('ERROR: El score dado es superior al valor máximo. Se devuelve la categoría más alta por defecto')\n",
    "            return (list(fairness_score.keys())[-1])\n",
    "        else:   \n",
    "            for k, v in fairness_score.items():\n",
    "                if score < v:\n",
    "                    return k\n",
    "                    break\n",
    "            \n",
    "            \n",
    "    def fit(self, df_dataset: pd.DataFrame, sensitive_cols: List[str], target_col: str, predict_col: str) -> List[Dict]:\n",
    "        \n",
    "        self.pre_processing(df_dataset=df_dataset, \n",
    "                            sensitive_cols=sensitive_cols, \n",
    "                            target_col=target_col, \n",
    "                            predict_col=predict_col)\n",
    "        \n",
    "        self.in_processing(df_dataset=df_dataset, \n",
    "                            sensitive_cols=sensitive_cols, \n",
    "                            target_col=target_col, \n",
    "                            predict_col=predict_col)\n",
    "        \n",
    "        self.post_processing(df_dataset=df_dataset, \n",
    "                            sensitive_cols=sensitive_cols, \n",
    "                            target_col=target_col, \n",
    "                            predict_col=predict_col)\n",
    "         \n",
    "        \n",
    "        metrics = list()\n",
    "        \n",
    "        for ground_truth in self.ground_truth_values:\n",
    "        \n",
    "            # Para cada una de las variables sensibles\n",
    "            for column in sensitive_cols:\n",
    "            \n",
    "                # Obtengo los distintos valores de la variable sensible; para ver si es o no binaria\n",
    "                sensitive_values = df_dataset[column].unique()\n",
    "                is_sensitive_col_binary = True if len(sensitive_values) == 2 else False\n",
    "            \n",
    "\n",
    "                # Para cada uno de los valores sensibles\n",
    "                for sensitive_value in sensitive_values:\n",
    "                    \n",
    "                    # Binarizo las predicciones y target del Dataset\n",
    "                    df_process = deepcopy(df_dataset)\n",
    "                    df_process.loc[df_process[target_col] != ground_truth, target_col] = self._OTHER\n",
    "                    df_process.loc[df_process[predict_col] != ground_truth, predict_col] = self._OTHER\n",
    "                    \n",
    "                    # Si sensitive feature es binaria -> \"1 sensitive feature\"\n",
    "                    if is_sensitive_col_binary:\n",
    "#                     if False:\n",
    "                        print(\"\\n{} - {} - {}\".format(column, \", \".join(sensitive_values), ground_truth))\n",
    "                        # Obtengo los resultados\n",
    "                        independence, separation, sufficience = self.fit_metrics(df=df_process,\n",
    "                                                                                 sensitive_col=column,\n",
    "                                                                                 target_col=target_col,\n",
    "                                                                                 predict_col=predict_col,\n",
    "                                                                                 ground_truth=ground_truth,\n",
    "                                                                                 sensitive_values=sensitive_values)\n",
    "                        score_weight = self.score_weight(df=df_process, \n",
    "                                                         groupby_cols=[predict_col], \n",
    "                                                         sensitive_col=column, \n",
    "                                                         predict_col=predict_col,\n",
    "                                                         ground_truth=ground_truth)\n",
    "                        score_weight_sufficience = self.score_weight(df=df_process, \n",
    "                                                         groupby_cols=[target_col], \n",
    "                                                         sensitive_col=column, \n",
    "                                                         predict_col=target_col,\n",
    "                                                         ground_truth=ground_truth)\n",
    "                        metrics.append({'Sensitive_Feature': column,\n",
    "                                        'is_Binary_Sensitive_feature': is_sensitive_col_binary,\n",
    "                                        'Sensitive_Value': \", \".join(sensitive_values),\n",
    "                                        'Ground_Truth': ground_truth, \n",
    "                                        'Independence_score': independence,\n",
    "                                        'Separation_score': separation,\n",
    "                                        'Sufficience_score': sufficience, \n",
    "                                        'Independence_Score_weight': score_weight,\n",
    "                                        'Separation_Score_weight': score_weight,\n",
    "                                        'Sufficience_Score_weight': score_weight_sufficience})\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"\\n{} - {} - {}\".format(column, sensitive_value, ground_truth))\n",
    "                        \n",
    "                        # Binarizo los valores sensibles para analizarlos de 1 en 1\n",
    "                        df_process.loc[df_process[column] != sensitive_value, column] = self._OTHER\n",
    "                        # Obtengo los resultados\n",
    "                        independence, separation, sufficience = self.fit_metrics(df=df_process,\n",
    "                                                                                 sensitive_col=column,\n",
    "                                                                                 target_col=target_col,\n",
    "                                                                                 predict_col=predict_col,\n",
    "                                                                                 ground_truth=ground_truth,\n",
    "                                                                                 sensitive_values=[sensitive_value, self._OTHER])\n",
    "                        score_weight = self.score_weight(df=df_process, \n",
    "                                                         groupby_cols=[column, predict_col], \n",
    "                                                         sensitive_col=column, \n",
    "                                                         predict_col=predict_col,\n",
    "                                                         ground_truth=ground_truth)\n",
    "                        score_weight_sufficience = self.score_weight(df=df_process, \n",
    "                                                         groupby_cols=[column, target_col], \n",
    "                                                         sensitive_col=column, \n",
    "                                                         predict_col=target_col,\n",
    "                                                         ground_truth=ground_truth)\n",
    "                        metrics.append({'Sensitive_Feature': column,\n",
    "                                        'is_Binary_Sensitive_feature': is_sensitive_col_binary,\n",
    "                                        'Sensitive_Value': sensitive_value,\n",
    "                                        'Ground_Truth': ground_truth,\n",
    "                                        'Independence_score': independence,\n",
    "                                        'Separation_score': separation, \n",
    "                                        'Sufficience_score': sufficience, \n",
    "                                        'Independence_Score_weight': score_weight,\n",
    "                                        'Separation_Score_weight': score_weight,\n",
    "                                        'Sufficience_Score_weight': score_weight_sufficience})\n",
    "            \n",
    "        return metrics\n",
    "    \n",
    "    \n",
    "    def fit_metrics(self, df: pd.DataFrame, sensitive_col: str, target_col: str, predict_col: str,\n",
    "                       ground_truth: str, sensitive_values: List[str]) -> Tuple[float, float, float]:\n",
    "        \n",
    "        independence = self.fit_independence(df=df,\n",
    "                                             sensitive_col=sensitive_col,\n",
    "                                             predict_col=predict_col,\n",
    "                                             ground_truth=ground_truth,\n",
    "                                             sensitive_values=sensitive_values)\n",
    "        print(\"Independence: {}\\n\".format(independence))\n",
    "        separation = self.fit_separation(df=df,\n",
    "                                         sensitive_col=sensitive_col,\n",
    "                                         target_col=target_col,\n",
    "                                         predict_col=predict_col,\n",
    "                                         ground_truth=ground_truth,\n",
    "                                         sensitive_values=sensitive_values)\n",
    "        print(\"Separation: {}\\n\".format(separation))\n",
    "        sufficience = self.fit_sufficiency(df=df,\n",
    "                                           sensitive_col=sensitive_col,\n",
    "                                           target_col=target_col,\n",
    "                                           predict_col=predict_col,\n",
    "                                           ground_truth=ground_truth,\n",
    "                                           sensitive_values=sensitive_values)\n",
    "        print(\"Sufficience: {}\\n\\n\".format(sufficience))\n",
    "        \n",
    "        return independence, separation, sufficience\n",
    "        \n",
    "    \n",
    "    def fit_independence(self, df: pd.DataFrame, sensitive_col: str, predict_col: str, \n",
    "                         ground_truth: str, sensitive_values: List[str]) -> float:\n",
    "        \"\"\"\n",
    "        A-> Variable sensible\n",
    "        Y-> Predicción\n",
    "        P(Y=y∣A=a) == P(Y=y∣A=b)\n",
    "        \"\"\"\n",
    "        prob_a = (((df[(df[sensitive_col]==sensitive_values[0]) & \n",
    "                       (df[predict_col]==ground_truth)].shape[0])) / \n",
    "                  (df[df[sensitive_col]==sensitive_values[0]].shape[0]))\n",
    "        prob_b = (((df[(df[sensitive_col]==sensitive_values[1]) & \n",
    "                       (df[predict_col]==ground_truth)].shape[0])) / \n",
    "                  (df[df[sensitive_col]==sensitive_values[1]].shape[0]))\n",
    "        \n",
    "        print('\\tProb A = {}'.format(prob_a))\n",
    "        print('\\tProb B = {}'.format(prob_b))\n",
    "        return abs(prob_a-prob_b)\n",
    "    \n",
    "    def fit_separation(self, df: pd.DataFrame, sensitive_col: str, target_col: str, predict_col: str,\n",
    "                       ground_truth: str, sensitive_values: List[str]) -> float:\n",
    "        \"\"\"      \n",
    "        A-> Variable sensible\n",
    "        Y-> Predicción\n",
    "        T-> Target\n",
    "        P(Y=1∣T=1,A=a)=P(Y=1∣T=1,A=b)\n",
    "        \"\"\"\n",
    "        prob_a = ((df[(df[sensitive_col]==sensitive_values[0]) &\n",
    "                      (df[target_col]==ground_truth) &\n",
    "                      (df[predict_col]==ground_truth)]).shape[0] / \n",
    "                  (df[(df[sensitive_col]==sensitive_values[0]) &\n",
    "                      (df[target_col]==ground_truth)]).shape[0])\n",
    "        prob_b = ((df[(df[sensitive_col]==sensitive_values[1]) &\n",
    "                      (df[target_col]==ground_truth) &\n",
    "                      (df[predict_col]==ground_truth)]).shape[0] / \n",
    "                  (df[(df[sensitive_col]==sensitive_values[1]) &\n",
    "                      (df[target_col]==ground_truth)]).shape[0])\n",
    "        \n",
    "        print('\\tProb A = {}'.format(prob_a))\n",
    "        print('\\tProb B = {}'.format(prob_b))\n",
    "        return abs(prob_a-prob_b)\n",
    "    \n",
    "    def fit_sufficiency(self, df: pd.DataFrame, sensitive_col: str, target_col: str, predict_col: str,\n",
    "                       ground_truth: str, sensitive_values: List[str]) -> float:\n",
    "        \"\"\"\n",
    "        A-> Variable sensible\n",
    "        Y-> Predicción\n",
    "        T-> Target\n",
    "        P(T=1∣Y=1,A=a)=P(T=1∣Y=1,A=b)\n",
    "        \"\"\"\n",
    "        prob_a = ((df[(df[sensitive_col]==sensitive_values[0]) &\n",
    "                      (df[target_col]==ground_truth) &\n",
    "                      (df[predict_col]==ground_truth)]).shape[0] / \n",
    "                  (df[(df[sensitive_col]==sensitive_values[0]) &\n",
    "                      (df[predict_col]==ground_truth)]).shape[0])\n",
    "        prob_b = ((df[(df[sensitive_col]==sensitive_values[1]) &\n",
    "                      (df[target_col]==ground_truth) &\n",
    "                      (df[predict_col]==ground_truth)]).shape[0] / \n",
    "                  (df[(df[sensitive_col]==sensitive_values[1]) &\n",
    "                      (df[predict_col]==ground_truth)]).shape[0])\n",
    "        \n",
    "        print('\\tProb A = {}'.format(prob_a))\n",
    "        print('\\tProb B = {}'.format(prob_b))\n",
    "        return abs(prob_a-prob_b)\n",
    "    \n",
    "    \n",
    "    def score_weight(self, df: pd.DataFrame, sensitive_col: str, \n",
    "                     predict_col: str, ground_truth: str, groupby_cols: List[str]) -> float:\n",
    "        \"\"\"\n",
    "        Función para calcular el porcentaje (peso) que supone el cálculo de algún criterio respecto se su\n",
    "        predicción y variable sensible\n",
    "        \"\"\"\n",
    "        dfp = df.groupby(groupby_cols)[sensitive_col].agg({'count' : 'count'}).reset_index()\n",
    "        dfp['pct'] = dfp['count'] / dfp['count'].sum()\n",
    "        return dfp[dfp[predict_col] == ground_truth]['pct'].iloc[0]\n",
    "            \n",
    "\n",
    "fairness = Fairness(fairness_params={})\n",
    "dict_result = fairness.fit(df_dataset=df_dataset,\n",
    "                           sensitive_cols=['Genero'],\n",
    "                           target_col='y_true', \n",
    "                           predict_col='y_predict')\n",
    "\n",
    "df_result = pd.DataFrame.from_dict(dict_result)\n",
    "df_result\n",
    "dict_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función de agregación del Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Definimos el Dataset de ejemplo\n",
    "df_score = pd.DataFrame(\n",
    "    {\n",
    "        'Ground_Truth': ['SI', 'SI', 'NO', 'NO'],\n",
    "        'Sensitive_Feature': ['Genero', 'Genero', 'Genero', 'Genero'],\n",
    "        'Sensitive_Value': ['Hombre', 'Mujer', 'Hombre', 'Mujer'],\n",
    "        'Independence_Score_weight': [0.4,      0.1,      0.2,      0.3],\n",
    "        'Independence_score':        [0.416667, 0.416667, 0.416667, 0.416667],\n",
    "        'Separation_Score_weight':   [0.4,      0.1,      0.2,      0.3],\n",
    "        'Separation_score':          [0.25,     0.25,     0.5,      0.5],\n",
    "        'Sufficience_Score_weight':  [0.4,      0.2,      0.2,      0.2],\n",
    "        'Sufficience_score':         [0.25,     0.25,     0.16,     0.16]}, \n",
    "    columns=['Ground_Truth', 'Sensitive_Value', 'Sensitive_Feature', 'Independence_Score_weight', \n",
    "             'Independence_score', 'Separation_Score_weight', 'Separation_score', 'Sufficience_Score_weight', \n",
    "             'Sufficience_score'])\n",
    "\n",
    "def global_score(df: pd.DataFrame, sensitive_cols: List[str]) -> Tuple[float, float, float]:\n",
    "    global_scores = list()\n",
    "    for sensitive_value in sensitive_cols:\n",
    "        print('Processing {} Feature'.format(sensitive_value))\n",
    "        df_filter = df[df['Sensitive_Feature'] == sensitive_value]\n",
    "        independence_score = np.average(a = df_filter['Independence_score'], weights = df_filter['Independence_Score_weight'])\n",
    "        separation_score = np.average(a = df_filter['Separation_score'], weights = df_filter['Separation_Score_weight'])\n",
    "        sufficience_score = np.average(a = df_filter['Sufficience_score'], weights = df_filter['Sufficience_Score_weight'])\n",
    "        global_scores.append({'Sensitive Value': sensitive_value,\n",
    "                              'independence score': independence_score,\n",
    "                              'separation score': separation_score,\n",
    "                              'sufficience score': sufficience_score})\n",
    "    return global_scores\n",
    "\n",
    "print(global_score(df=df_score, sensitive_cols=['Genero']))\n",
    "\n",
    "df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_score(df=df_result, sensitive_cols=['Genero'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fairness_score(score: float, fairness_score: Dict):\n",
    "    # Ordenamos el diccionario con los valores de menor a mayor\n",
    "    try:\n",
    "        fairness_score = dict(sorted(fairness_score.items(), key=lambda item: item[1], reverse=False))\n",
    "    except:\n",
    "        print('Error con el diccionario de Fairness Scores')\n",
    "    \n",
    "    if fairness_score[(list(fairness_score.keys())[-1])] < score:\n",
    "        print('ERROR: El score dado es superior al valor máximo. Se devuelve la categoría más alta por defecto')\n",
    "        return (list(fairness_score.keys())[-1])\n",
    "    else:   \n",
    "        for k, v in fairness_score.items():\n",
    "            if score < v:\n",
    "                return k\n",
    "                break\n",
    "    \n",
    "get_fairness_score(score=0.01, fairness_score=FAIRNESS_SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(FAIRNESS_SCORE.keys())[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Ejemplo de aplicación real - Clasificación Binaria\n",
    "\n",
    "\n",
    "\n",
    "## 1.- Lectura del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Leemos el dataset\n",
    "df = pd.read_csv('../../datasets/bodyPerformance.csv')\n",
    "print('Tamaño del dataset {}'.format(df.shape))\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rango_edad'] = df['age'].apply(lambda x: 10 if x < 20 \n",
    "                                   else (20 if (x >= 20 and x < 30) \n",
    "                                         else (30 if (x >= 30 and x < 40) \n",
    "                                               else (40 if (x >= 40 and x < 50) \n",
    "                                                     else (50 if (x >= 50 and x < 60) \n",
    "                                                           else 60)))))\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribución del target por género"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = df.groupby(['gender', 'class'])['age'].agg({'count' : 'count'}).reset_index()\n",
    "dfp['perc'] = dfp.groupby('gender')['count'].apply(lambda x: x*100/x.sum())\n",
    "dfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para clasificación binaria me quedo con las clases B y D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df['class'].isin(['B', 'D'])].rename({'class': 'y_true'}, axis=1)\n",
    "df = df[df['class'].isin(['A', 'B', 'C' , 'D'])].rename({'class': 'y_true'}, axis=1)\n",
    "print('Tamaño del dataset {}'.format(df.shape))\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 2.- Modelo & Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Codificamos las variables discretas\n",
    "lb_gen = LabelEncoder()\n",
    "lb_y = LabelEncoder()\n",
    "df['gender'] = lb_gen.fit_transform(df['gender'])\n",
    "df['y_true'] = lb_y.fit_transform(df['y_true'])\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Creamos y entrenamos el modelo\n",
    "model = LogisticRegression()\n",
    "model.fit(df[df.columns[:-2]], df[df.columns[-2]])\n",
    "print('Accuracy: {}'.format(model.score(df[df.columns[:-2]], df[df.columns[-2]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos las predicciones\n",
    "df['y_predict'] = model.predict(df[df.columns[:-2]])\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deshacemos en LabelEncoder de la variable género, target y predicción\n",
    "df['gender'] = lb_gen.inverse_transform(df['gender'])\n",
    "df['y_true'] = lb_y.inverse_transform(df['y_true'])\n",
    "df['y_predict'] = lb_y.inverse_transform(df['y_predict'])\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- Criterio de Independencia (Binario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fairness = Fairness(fairness_params={})\n",
    "# dict_result = fairness.fit_fairness(df_dataset=df, sensitive_cols=['gender'], target_col='y_true', predict_col='y_predict')\n",
    "# dict_result = fairness.fit_fairness(df_dataset=df, sensitive_cols=['rango_edad'], target_col='y_true', predict_col='y_predict')\n",
    "dict_result = fairness.fit_fairness(df_dataset=df, sensitive_cols=['gender', 'rango_edad'], target_col='y_true', predict_col='y_predict')\n",
    "df_result = pd.DataFrame.from_dict(dict_result)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_score(df=df_result, sensitive_cols=['gender', 'rango_edad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness.confusion_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
